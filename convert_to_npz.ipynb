{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmp09\\AUDIO_DIR\\fma_small\n"
     ]
    }
   ],
   "source": [
    "RAW_DIR = os.environ.get('RAW_AUDIO')\n",
    "print(RAW_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tids_from_directory(audio_dir):\n",
    "    \"\"\"Get track IDs from the mp3s in a directory.\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_dir : str\n",
    "        Path to the directory where the audio files are stored.\n",
    "    Returns\n",
    "    -------\n",
    "        A list of track IDs.\n",
    "    \"\"\"\n",
    "    tids = []\n",
    "    for _, dirnames, files in os.walk(audio_dir):\n",
    "        if dirnames == []:\n",
    "            tids.extend(int(file[:-4]) for file in files)\n",
    "    return tids\n",
    "\n",
    "\n",
    "def get_audio_path(audio_dir, track_id):\n",
    "    \"\"\"\n",
    "    Return the path to the mp3 given the directory where the audio is stored\n",
    "    and the track ID.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import utils\n",
    "    >>> AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "    >>> utils.get_audio_path(AUDIO_DIR, 2)\n",
    "    '../data/fma_small/000/000002.mp3'\n",
    "    \"\"\"\n",
    "    tid_str = '{:06d}'.format(track_id)\n",
    "    print(tid_str)\n",
    "    return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "tids = get_tids_from_directory(str(RAW_DIR))\n",
    "print(len(tids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectogram(track_id):\n",
    "    filename = get_audio_path(RAW_DIR, track_id)\n",
    "    y, sr = lb.load(str(filename))\n",
    "    spect = lb.feature.melspectrogram(y=y, sr=sr,n_fft=2048, hop_length=1024)\n",
    "    spect = lb.power_to_db(spect, ref=np.max)\n",
    "    return spect.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spect(track_id):\n",
    "    spect = create_spectogram(track_id)\n",
    "    print(spect.shape)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spect.T, y_axis='mel', fmax=8000, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000005\n"
     ]
    },
    {
     "ename": "NoBackendError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoBackendError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-74096a00e51f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_spect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-82e69f2d4183>\u001b[0m in \u001b[0;36mplot_spect\u001b[1;34m(track_id)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_spect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mspect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_spectogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-407d07047161>\u001b[0m in \u001b[0;36mcreate_spectogram\u001b[1;34m(track_id)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_spectogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_audio_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRAW_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mspect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mspect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower_to_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;31m# All backends failed!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNoBackendError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoBackendError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_spect(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset with genre and track IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">set</th>\n",
       "      <th>track</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>genre_top</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>Pop</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>Folk</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>Folk</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               set            track track_id\n",
       "             split subset genre_top         \n",
       "track_id                                    \n",
       "2         training  small   Hip-Hop        2\n",
       "5         training  small   Hip-Hop        5\n",
       "10        training  small       Pop       10\n",
       "140       training  small      Folk      140\n",
       "141       training  small      Folk      141"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'audio_files/tracks.csv'\n",
    "tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "keep_cols = [('set', 'split'),\n",
    "('set', 'subset'),('track', 'genre_top')]\n",
    "\n",
    "df_all = tracks[keep_cols]\n",
    "df_all = df_all[df_all[('set', 'subset')] == 'small']\n",
    "\n",
    "df_all['track_id'] = df_all.index\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hip-Hop', 'Pop', 'Folk', 'Experimental', 'Rock', 'International',\n",
       "       'Electronic', 'Instrumental'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[('track', 'genre_top')].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_genres = {'Electronic':1, 'Experimental':2, 'Folk':3, 'Hip-Hop':4, \n",
    "               'Instrumental':5,'International':6, 'Pop' :7, 'Rock': 8  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array(df):\n",
    "    genres = []\n",
    "    X_spect = np.empty((0, 640, 128))\n",
    "    count = 0\n",
    "    #Code skips records in case of errors\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            count += 1\n",
    "            track_id = int(row['track_id'])\n",
    "            genre = str(row[('track', 'genre_top')])\n",
    "            spect = create_spectogram(track_id)\n",
    "\n",
    "            # Normalize for small shape differences\n",
    "            spect = spect[:640, :]\n",
    "            X_spect = np.append(X_spect, [spect], axis=0)\n",
    "            genres.append(dict_genres[genre])\n",
    "            if count % 100 == 0:\n",
    "                print(\"Currently processing: \", count)\n",
    "        except:\n",
    "            print(\"Couldn't process: \", count)\n",
    "            continue\n",
    "    y_arr = np.array(genres)\n",
    "    return X_spect, y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['training', 'validation', 'test'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[('set', 'split')].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, validation and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 4) (800, 4) (800, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_all[df_all[('set', 'split')]=='training']\n",
    "df_valid = df_all[df_all[('set', 'split')]=='validation']\n",
    "df_test = df_all[df_all[('set', 'split')]=='test']\n",
    "\n",
    "print(df_train.shape, df_valid.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  100\n",
      "Currently processing:  200\n",
      "Currently processing:  300\n",
      "Currently processing:  400\n",
      "Currently processing:  500\n",
      "Currently processing:  600\n",
      "Currently processing:  700\n",
      "Currently processing:  800\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = create_array(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 640, 128) (800,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 6 6 6 6 6 6 3 3 2 2 2 2 2 2 8 8 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('test_arr', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  100\n",
      "Currently processing:  200\n",
      "Currently processing:  300\n",
      "Currently processing:  400\n",
      "Currently processing:  500\n",
      "Currently processing:  600\n",
      "Currently processing:  700\n",
      "Currently processing:  800\n"
     ]
    }
   ],
   "source": [
    "X_valid, y_valid = create_array(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('valid_arr', X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Train data split into 4 chunks to do the slow pre-processing in phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataFrameIntoSmaller(df, chunkSize = 1600): \n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])\n",
    "    return listOfDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 4) (1600, 4) (1600, 4) (1600, 4)\n"
     ]
    }
   ],
   "source": [
    "listDf = splitDataFrameIntoSmaller(df_train)\n",
    "df1_train = listDf[0]\n",
    "df2_train = listDf[1]\n",
    "df3_train = listDf[2]\n",
    "df4_train = listDf[3]\n",
    "print(df1_train.shape, df2_train.shape, df3_train.shape, df4_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  100\n",
      "Currently processing:  200\n",
      "Currently processing:  300\n",
      "Currently processing:  400\n",
      "Currently processing:  500\n",
      "Currently processing:  600\n",
      "Currently processing:  700\n",
      "Currently processing:  800\n",
      "Currently processing:  900\n",
      "Currently processing:  1000\n",
      "Currently processing:  1100\n",
      "Currently processing:  1200\n",
      "Currently processing:  1300\n",
      "Currently processing:  1400\n",
      "Currently processing:  1500\n",
      "Currently processing:  1600\n"
     ]
    }
   ],
   "source": [
    "X_train1, y_train1 = create_array(df1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train1_arr', X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  100\n",
      "Currently processing:  200\n",
      "Currently processing:  300\n",
      "Currently processing:  400\n",
      "Currently processing:  500\n",
      "Currently processing:  600\n",
      "Currently processing:  700\n",
      "Currently processing:  800\n",
      "Currently processing:  900\n",
      "Currently processing:  1000\n",
      "Currently processing:  1100\n",
      "Currently processing:  1200\n",
      "Currently processing:  1300\n",
      "Currently processing:  1400\n",
      "Currently processing:  1500\n",
      "Currently processing:  1600\n"
     ]
    }
   ],
   "source": [
    "X_train2, y_train2 = create_array(df2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train2_arr', X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  100\n",
      "Currently processing:  200\n",
      "Couldn't process:  296\n",
      "Couldn't process:  297\n",
      "Couldn't process:  298\n",
      "Currently processing:  300\n",
      "Couldn't process:  331\n",
      "Currently processing:  400\n",
      "Currently processing:  500\n",
      "Currently processing:  600\n",
      "Couldn't process:  698\n",
      "Currently processing:  700\n",
      "Currently processing:  800\n",
      "Currently processing:  900\n",
      "Currently processing:  1000\n",
      "Currently processing:  1100\n",
      "Currently processing:  1200\n",
      "Currently processing:  1300\n",
      "Currently processing:  1400\n",
      "Currently processing:  1500\n",
      "Currently processing:  1600\n"
     ]
    }
   ],
   "source": [
    "X_train3, y_train3 = create_array(df3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1595, 640, 128) (1595,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train3.shape, y_train3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train3_arr', X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  100\n",
      "Currently processing:  200\n",
      "Currently processing:  300\n",
      "Currently processing:  400\n",
      "Currently processing:  500\n",
      "Currently processing:  600\n",
      "Currently processing:  700\n",
      "Currently processing:  800\n",
      "Couldn't process:  812\n",
      "Currently processing:  900\n",
      "Currently processing:  1000\n",
      "Currently processing:  1100\n",
      "Currently processing:  1200\n",
      "Currently processing:  1300\n",
      "Currently processing:  1400\n",
      "Currently processing:  1500\n",
      "Currently processing:  1600\n"
     ]
    }
   ],
   "source": [
    "X_train4, y_train4 = create_array(df4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train4_arr', X_train4, y_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 640, 128) (1599,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train4.shape, y_train4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate and Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('train1_arr.npz')\n",
    "print(npzfile.files)\n",
    "X_train1 = npzfile['arr_0']\n",
    "y_train1 = npzfile['arr_1']\n",
    "print(X_train1.shape, y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('train2_arr.npz')\n",
    "print(npzfile.files)\n",
    "X_train2 = npzfile['arr_0']\n",
    "y_train2 = npzfile['arr_1']\n",
    "print(X_train2.shape, y_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('train3_arr.npz')\n",
    "print(npzfile.files)\n",
    "X_train3 = npzfile['arr_0']\n",
    "y_train3 = npzfile['arr_1']\n",
    "print(X_train3.shape, y_train3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('train4_arr.npz')\n",
    "print(npzfile.files)\n",
    "X_train4 = npzfile['arr_0']\n",
    "y_train4 = npzfile['arr_1']\n",
    "print(X_train4.shape, y_train4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('valid_arr.npz')\n",
    "print(npzfile.files)\n",
    "X_valid = npzfile['arr_0']\n",
    "y_valid = npzfile['arr_1']\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train1, X_train2, X_train3, X_train4), axis = 0)\n",
    "y_train = np.concatenate((y_train1, y_train2, y_train3, y_train4), axis = 0)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert y data from scale 0-7\n",
    "print(np.amin(X_train), np.amax(X_train), np.mean(X_train))\n",
    "y_train = y_train -1\n",
    "y_valid = y_valid -1\n",
    "print(np.amin(y_train), np.amax(y_train), np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert the scale of training data\n",
    "X_train_raw = librosa.core.db_to_power(X_train, ref=1.0)\n",
    "print(np.amin(X_train_raw), np.amax(X_train_raw), np.mean(X_train_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_log = np.log(X_train_raw)\n",
    "print(np.amin(X_train_log), np.amax(X_train_log), np.mean(X_train_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_raw = librosa.core.db_to_power(X_valid, ref=1.0)\n",
    "X_valid_log = np.log(X_valid_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "X_train, y_train = unison_shuffled_copies(X_train_log, y_train)\n",
    "X_valid, y_valid = unison_shuffled_copies(X_valid_log, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shapes are: \", X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('shuffled_train', X_train, y_train)\n",
    "np.savez('shuffled_valid', X_valid, y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

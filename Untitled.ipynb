{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3bae9d7c3bf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdotenv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import pydot\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ctypes\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import multiprocessing.sharedctypes as sharedctypes\n",
    "import os.path\n",
    "import ast\n",
    "\n",
    "\n",
    "# Number of samples per 30s audio clip.\n",
    "# TODO: fix dataset to be constant.\n",
    "NB_AUDIO_SAMPLES = 1321967\n",
    "SAMPLING_RATE = 44100\n",
    "\n",
    "# Load the environment from the .env file.\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "\n",
    "\n",
    "class FreeMusicArchive:\n",
    "\n",
    "    BASE_URL = 'https://freemusicarchive.org/api/get/'\n",
    "\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "\n",
    "    def get_recent_tracks(self):\n",
    "        URL = 'https://freemusicarchive.org/recent.json'\n",
    "        r = requests.get(URL)\n",
    "        r.raise_for_status()\n",
    "        tracks = []\n",
    "        artists = []\n",
    "        date_created = []\n",
    "        for track in r.json()['aTracks']:\n",
    "            tracks.append(track['track_id'])\n",
    "            artists.append(track['artist_name'])\n",
    "            date_created.append(track['track_date_created'])\n",
    "        return tracks, artists, date_created\n",
    "\n",
    "    def _get_data(self, dataset, fma_id, fields=None):\n",
    "        url = self.BASE_URL + dataset + 's.json?'\n",
    "        url += dataset + '_id=' + str(fma_id) + '&api_key=' + self.api_key\n",
    "        # print(url)\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        if r.json()['errors']:\n",
    "            raise Exception(r.json()['errors'])\n",
    "        data = r.json()['dataset'][0]\n",
    "        r_id = data[dataset + '_id']\n",
    "        if r_id != str(fma_id):\n",
    "            raise Exception('The received id {} does not correspond to'\n",
    "                            'the requested one {}'.format(r_id, fma_id))\n",
    "        if fields is None:\n",
    "            return data\n",
    "        if type(fields) is list:\n",
    "            ret = {}\n",
    "            for field in fields:\n",
    "                ret[field] = data[field]\n",
    "            return ret\n",
    "        else:\n",
    "            return data[fields]\n",
    "\n",
    "    def get_track(self, track_id, fields=None):\n",
    "        return self._get_data('track', track_id, fields)\n",
    "\n",
    "    def get_album(self, album_id, fields=None):\n",
    "        return self._get_data('album', album_id, fields)\n",
    "\n",
    "    def get_artist(self, artist_id, fields=None):\n",
    "        return self._get_data('artist', artist_id, fields)\n",
    "\n",
    "    def get_all(self, dataset, id_range):\n",
    "        index = dataset + '_id'\n",
    "\n",
    "        id_ = 2 if dataset is 'track' else 1\n",
    "        row = self._get_data(dataset, id_)\n",
    "        df = pd.DataFrame(columns=row.keys())\n",
    "        df.set_index(index, inplace=True)\n",
    "\n",
    "        not_found_ids = []\n",
    "\n",
    "        for id_ in id_range:\n",
    "            try:\n",
    "                row = self._get_data(dataset, id_)\n",
    "            except:\n",
    "                not_found_ids.append(id_)\n",
    "                continue\n",
    "            row.pop(index)\n",
    "            df = df.append(pd.Series(row, name=id_))\n",
    "\n",
    "        return df, not_found_ids\n",
    "\n",
    "    def download_track(self, track_file, path):\n",
    "        url = 'https://files.freemusicarchive.org/' + track_file\n",
    "        r = requests.get(url, stream=True)\n",
    "        r.raise_for_status()\n",
    "        with open(path, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    def get_track_genres(self, track_id):\n",
    "        genres = self.get_track(track_id, 'track_genres')\n",
    "        genre_ids = []\n",
    "        genre_titles = []\n",
    "        for genre in genres:\n",
    "            genre_ids.append(genre['genre_id'])\n",
    "            genre_titles.append(genre['genre_title'])\n",
    "        return genre_ids, genre_titles\n",
    "\n",
    "    def get_all_genres(self):\n",
    "        df = pd.DataFrame(columns=['genre_parent_id', 'genre_title',\n",
    "                                   'genre_handle', 'genre_color'])\n",
    "        df.index.rename('genre_id', inplace=True)\n",
    "\n",
    "        page = 1\n",
    "        while True:\n",
    "            url = self.BASE_URL + 'genres.json?limit=50'\n",
    "            url += '&page={}&api_key={}'.format(page, self.api_key)\n",
    "            r = requests.get(url)\n",
    "            for genre in r.json()['dataset']:\n",
    "                genre_id = int(genre.pop(df.index.name))\n",
    "                df.loc[genre_id] = genre\n",
    "            assert (r.json()['page'] == str(page))\n",
    "            page += 1\n",
    "            if page > r.json()['total_pages']:\n",
    "                break\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "class Genres:\n",
    "\n",
    "    def __init__(self, genres_df):\n",
    "        self.df = genres_df\n",
    "\n",
    "    def create_tree(self, roots, depth=None):\n",
    "\n",
    "        if type(roots) is not list:\n",
    "            roots = [roots]\n",
    "        graph = pydot.Dot(graph_type='digraph', strict=True)\n",
    "\n",
    "        def create_node(genre_id):\n",
    "            title = self.df.at[genre_id, 'title']\n",
    "            ntracks = self.df.at[genre_id, '#tracks']\n",
    "            #name = self.df.at[genre_id, 'title'] + '\\n' + str(genre_id)\n",
    "            name = '\"{}\\n{} / {}\"'.format(title, genre_id, ntracks)\n",
    "            return pydot.Node(name)\n",
    "\n",
    "        def create_tree(root_id, node_p, depth):\n",
    "            if depth == 0:\n",
    "                return\n",
    "            children = self.df[self.df['parent'] == root_id]\n",
    "            for child in children.iterrows():\n",
    "                genre_id = child[0]\n",
    "                node_c = create_node(genre_id)\n",
    "                graph.add_edge(pydot.Edge(node_p, node_c))\n",
    "                create_tree(genre_id, node_c,\n",
    "                            depth-1 if depth is not None else None)\n",
    "\n",
    "        for root in roots:\n",
    "            node_p = create_node(root)\n",
    "            graph.add_node(node_p)\n",
    "            create_tree(root, node_p, depth)\n",
    "\n",
    "        return graph\n",
    "\n",
    "    def find_roots(self):\n",
    "        roots = []\n",
    "        for gid, row in self.df.iterrows():\n",
    "            parent = row['parent']\n",
    "            title = row['title']\n",
    "            if parent == 0:\n",
    "                roots.append(gid)\n",
    "            elif parent not in self.df.index:\n",
    "                msg = '{} ({}) has parent {} which is missing'.format(\n",
    "                        gid, title, parent)\n",
    "                raise RuntimeError(msg)\n",
    "        return roots\n",
    "\n",
    "\n",
    "def load(filepath):\n",
    "\n",
    "    filename = os.path.basename(filepath)\n",
    "\n",
    "    if 'features' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'echonest' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'genres' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0)\n",
    "\n",
    "    if 'tracks' in filename:\n",
    "        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "\n",
    "        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
    "                   ('track', 'genres'), ('track', 'genres_all'),\n",
    "                   ('track', 'genres_top')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].map(ast.literal_eval)\n",
    "\n",
    "        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
    "                   ('album', 'date_created'), ('album', 'date_released'),\n",
    "                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
    "                   ('artist', 'active_year_end')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = pd.to_datetime(tracks[column])\n",
    "\n",
    "        SUBSETS = ('small', 'medium', 'large')\n",
    "        tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                'category', categories=SUBSETS, ordered=True)\n",
    "\n",
    "        COLUMNS = [('track', 'license'), ('artist', 'bio'),\n",
    "                   ('album', 'type'), ('album', 'information')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].astype('category')\n",
    "\n",
    "        return tracks\n",
    "\n",
    "\n",
    "def get_audio_path(audio_dir, track_id):\n",
    "    \"\"\"\n",
    "    Return the path to the mp3 given the directory where the audio is stored\n",
    "    and the track ID.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import utils\n",
    "    >>> AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "    >>> utils.get_audio_path(AUDIO_DIR, 2)\n",
    "    '../data/fma_small/000/000002.mp3'\n",
    "\n",
    "    \"\"\"\n",
    "    tid_str = '{:06d}'.format(track_id)\n",
    "    return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')\n",
    "\n",
    "\n",
    "def get_tids_from_directory(audio_dir):\n",
    "    \"\"\"Get track IDs from the mp3s in a directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_dir : str\n",
    "        Path to the directory where the audio files are stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A list of track IDs.\n",
    "    \"\"\"\n",
    "    tids = []\n",
    "    for _, dirnames, files in os.walk(audio_dir):\n",
    "        if dirnames == []:\n",
    "            tids.extend(int(file[:-4]) for file in files)\n",
    "    return tids\n",
    "\n",
    "\n",
    "class Loader:\n",
    "    def load(self, filepath):\n",
    "        raise NotImplemented()\n",
    "\n",
    "\n",
    "class RawAudioLoader(Loader):\n",
    "    def __init__(self, sampling_rate=SAMPLING_RATE):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.shape = (NB_AUDIO_SAMPLES * sampling_rate // SAMPLING_RATE, )\n",
    "\n",
    "    def load(self, filepath):\n",
    "        return self._load(filepath)[:self.shape[0]]\n",
    "\n",
    "\n",
    "class LibrosaLoader(RawAudioLoader):\n",
    "    def _load(self, filepath):\n",
    "        import librosa\n",
    "        sr = self.sampling_rate if self.sampling_rate != SAMPLING_RATE else None\n",
    "        # kaiser_fast is 3x faster than kaiser_best\n",
    "        #x, sr = librosa.load(filepath, sr=sr, res_type='kaiser_fast')\n",
    "        x, sr = librosa.load(filepath, sr=sr)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AudioreadLoader(RawAudioLoader):\n",
    "    def _load(self, filepath):\n",
    "        import audioread\n",
    "        a = audioread.audio_open(filepath)\n",
    "        a.read_data()\n",
    "\n",
    "\n",
    "class PydubLoader(RawAudioLoader):\n",
    "    def _load(self, filepath):\n",
    "        from pydub import AudioSegment\n",
    "        song = AudioSegment.from_file(filepath)\n",
    "        song = song.set_channels(1)\n",
    "        x = song.get_array_of_samples()\n",
    "        # print(filepath) if song.channels != 2 else None\n",
    "        return np.array(x)\n",
    "\n",
    "\n",
    "class FfmpegLoader(RawAudioLoader):\n",
    "    def _load(self, filepath):\n",
    "        \"\"\"Fastest and less CPU intensive loading method.\"\"\"\n",
    "        import subprocess as sp\n",
    "        command = ['ffmpeg',\n",
    "                   '-i', filepath,\n",
    "                   '-f', 's16le',\n",
    "                   '-acodec', 'pcm_s16le',\n",
    "                   '-ac', '1']  # channels: 2 for stereo, 1 for mono\n",
    "        if self.sampling_rate != SAMPLING_RATE:\n",
    "            command.extend(['-ar', str(self.sampling_rate)])\n",
    "        command.append('-')\n",
    "        # 30s at 44.1 kHz ~= 1.3e6\n",
    "        proc = sp.run(command, stdout=sp.PIPE, bufsize=10**7, stderr=sp.DEVNULL, check=True)\n",
    "\n",
    "        return np.fromstring(proc.stdout, dtype=\"int16\")\n",
    "\n",
    "\n",
    "def build_sample_loader(audio_dir, Y, loader):\n",
    "\n",
    "    class SampleLoader:\n",
    "\n",
    "        def __init__(self, tids, batch_size=4):\n",
    "            self.lock1 = multiprocessing.Lock()\n",
    "            self.lock2 = multiprocessing.Lock()\n",
    "            self.batch_foremost = sharedctypes.RawValue(ctypes.c_int, 0)\n",
    "            self.batch_rearmost = sharedctypes.RawValue(ctypes.c_int, -1)\n",
    "            self.condition = multiprocessing.Condition(lock=self.lock2)\n",
    "\n",
    "            data = sharedctypes.RawArray(ctypes.c_int, tids.data)\n",
    "            self.tids = np.ctypeslib.as_array(data)\n",
    "\n",
    "            self.batch_size = batch_size\n",
    "            self.loader = loader\n",
    "            self.X = np.empty((self.batch_size, *loader.shape))\n",
    "            self.Y = np.empty((self.batch_size, Y.shape[1]), dtype=np.int)\n",
    "\n",
    "        def __iter__(self):\n",
    "            return self\n",
    "\n",
    "        def __next__(self):\n",
    "\n",
    "            with self.lock1:\n",
    "                if self.batch_foremost.value == 0:\n",
    "                    np.random.shuffle(self.tids)\n",
    "\n",
    "                batch_current = self.batch_foremost.value\n",
    "                if self.batch_foremost.value + self.batch_size < self.tids.size:\n",
    "                    batch_size = self.batch_size\n",
    "                    self.batch_foremost.value += self.batch_size\n",
    "                else:\n",
    "                    batch_size = self.tids.size - self.batch_foremost.value\n",
    "                    self.batch_foremost.value = 0\n",
    "\n",
    "                # print(self.tids, self.batch_foremost.value, batch_current, self.tids[batch_current], batch_size)\n",
    "                # print('queue', self.tids[batch_current], batch_size)\n",
    "                tids = np.array(self.tids[batch_current:batch_current+batch_size])\n",
    "\n",
    "            for i, tid in enumerate(tids):\n",
    "                self.X[i] = self.loader.load(get_audio_path(audio_dir, tid))\n",
    "                self.Y[i] = Y.loc[tid]\n",
    "\n",
    "            with self.lock2:\n",
    "                while (batch_current - self.batch_rearmost.value) % self.tids.size > self.batch_size:\n",
    "                    # print('wait', indices[0], batch_current, self.batch_rearmost.value)\n",
    "                    self.condition.wait()\n",
    "                self.condition.notify_all()\n",
    "                # print('yield', indices[0], batch_current, self.batch_rearmost.value)\n",
    "                self.batch_rearmost.value = batch_current\n",
    "\n",
    "                return self.X[:batch_size], self.Y[:batch_size]\n",
    "\n",
    "    return SampleLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'audio_files/tracks.csv' does not exist: b'audio_files/tracks.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-13c1b93eabe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Directory where mp3 are stored.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'audio_files/tracks.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtracks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtracks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'audio_files/tracks.csv' does not exist: b'audio_files/tracks.csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
